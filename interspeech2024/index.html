<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="UTF-8">
    <title>Predicting Acute Pain Levels Implicitly from Vocal Features</title>
    <link rel="stylesheet" type="text/css" href="../../stylesheet.css"/>
  </head>
  <body>
    <div>
      <article>
        <header>
          <h1>Mel Spectrogram Samples for "Predicting Acute Pain Levels Implicitly from Vocal Features"</h1>
        </header>
      </article>

      <p><b>Paper:</b> Under Review</a></p>
      <p><b>Authors:</b> Anonymous
      </p>

      <p><b>Abstract:</b>
        Evaluating pain through speech represents a critical challenge in high-stakes clinical scenarios, from analgesia delivery to emergency triage. Clinicians have predominantly relied on direct verbal communication of pain which is difficult for patients with communication barriers, such as those affected by stroke, autism, and learning difficulties. Many previous efforts have focused on multimodal data which does not suit all clinical applications. Our work introduces a new dataset wherein we have induced acute pain for adult study participants in a cold pressor task protocol and recorded subjects reading English sentences out loud. We report discrimination performance as F1 scores from binary (pain vs. no pain) and three-class (mild, moderate, severe) prediction tasks and support our results with explainable feature analysis. Our approach has the potential to provide decision support for pain evaluation to improve care across diverse and remote medical settings.
      </p>

      <p></p>

    
</body>
</html>

